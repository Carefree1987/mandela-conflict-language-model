# Emergent Semantic Instability in Probabilistic Language Models
### *Independent Observation Report by Dennis Sorgenfrei*

This repository contains a bilingual (German–English) case study documenting an observed **semantic instability** 
in GPT-5 during a live interaction.  
The incident mirrors a "Mandela Effect" – a collective false memory statistically reproduced inside the model’s probability space.

---

## 🧠 Overview
In October 2025, a factual query about the existence of a "seahorse emoji" triggered an internal conflict 
between two competing truth clusters ("exists" vs. "does not exist").  
The model produced contradictory outputs before self-correcting.  
This event revealed an emergent instability in the model’s semantic structure.

---

## 📄 Contents
- **PDF Report:** [Emergente_semantische_Instabilitaet_Dennis_Sorgenfrei.pdf](./Emergente_semantische_Instabilitaet_Dennis_Sorgenfrei.pdf)
- **Language:** German & English
- **Author:** Dennis Sorgenfrei  
- **Date:** October 23, 2025  

---

## 🔍 Relevance
The case provides a real-world example of:
- probabilistic drift and data bias,  
- cognitive dissonance analogues in neural systems,  
- self-regulation and correction in large language models.

It bridges psychology, statistics, and machine learning – a micro-study of *emergent reasoning* in AI.

---

**License:** CC BY 4.0 – free to share and reference with attribution.
