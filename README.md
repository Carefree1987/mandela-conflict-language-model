# Emergent Semantic Instability in Probabilistic Language Models
### *Independent Observation Report by Dennis Sorgenfrei*

This repository contains a bilingual (Germanâ€“English) case study documenting an observed **semantic instability** 
in GPT-5 during a live interaction.  
The incident mirrors a "Mandela Effect" â€“ a collective false memory statistically reproduced inside the modelâ€™s probability space.

---

## ğŸ§  Overview
In October 2025, a factual query about the existence of a "seahorse emoji" triggered an internal conflict 
between two competing truth clusters ("exists" vs. "does not exist").  
The model produced contradictory outputs before self-correcting.  
This event revealed an emergent instability in the modelâ€™s semantic structure.

---

## ğŸ“„ Contents
- **PDF Report:** [Emergente_semantische_Instabilitaet_Dennis_Sorgenfrei.pdf](./Emergente_semantische_Instabilitaet_Dennis_Sorgenfrei.pdf)
- **Language:** German & English
- **Author:** Dennis Sorgenfrei  
- **Date:** October 23, 2025  

---

## ğŸ” Relevance
The case provides a real-world example of:
- probabilistic drift and data bias,  
- cognitive dissonance analogues in neural systems,  
- self-regulation and correction in large language models.

It bridges psychology, statistics, and machine learning â€“ a micro-study of *emergent reasoning* in AI.

---

**License:** CC BY 4.0 â€“ free to share and reference with attribution.
